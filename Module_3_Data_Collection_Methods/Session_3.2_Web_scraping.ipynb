{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26acf247",
   "metadata": {},
   "source": [
    "<img src='images/gesis.png' style='height: 60px; float: left'>\n",
    "<img src='images/social_comquant.png' style='height: 50px; float: left; margin-left: 40px'>\n",
    "<img src='images/isi.png' style='height: 50px; float: left; margin-left: 20px'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c8be6",
   "metadata": {},
   "source": [
    "Authors = \n",
    "\n",
    "Date = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4ea4a",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Data collection is a procedure of gathering information from subjects (all relevant sources), measuring and analyzing accurate insights for research using various techniques. Researchers can evaluate their research questions and hypotheses on the basis of collected data. In most cases, data collection is the primary and most important step for research, irrespective of the field of study. The approach of data collection varies for different fields of study, depending on the required information.\n",
    "\n",
    "The internet is an absolutely massive source of data which we can access by various ways such as connecting APIs (see Teaching Module 3.1. API harvesting). In addtion to APIs, web scraping is often the only way we can access data that it is not available in convenient CSV exports or APIs. Websites are often valuable sources of data; for example, weather forecasts, comments on news sites, and posts on forums. To access those sorts of information on webpages, we will use web scraping.\n",
    "\n",
    "With this online module, we are going to show how to do web scraping with Python from scratch. Then, we will work through an actual web scraping project, focusing on ??? data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66abdeec",
   "metadata": {},
   "source": [
    "# 2. Fundamentals of Web scarping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403de1f",
   "metadata": {},
   "source": [
    "<img src=\"./images/webscrape.png\"  width=\"350\" height = \"350\" align=\"center\"/>\n",
    "\n",
    "In order to access APIs, you first need to create an account and apply to have a developer account on the platform that you want to work on. With this developer account, platforms provide you KEYS (e.g., secret, public, or access) to authenticate their system.\n",
    "\n",
    "While web scraping is one of the common ways of collecting data from websites, a lot of websites offer APIs to access the public data that they host on their website. This is to avoid unnecessary traffic on the websites.\n",
    "\n",
    "However, even though we have access to these API, as researchers, we should not forget to respect API access rules and always read the documents before collecting data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09370b8",
   "metadata": {},
   "source": [
    "## 2.1. HTML for Web Scraping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8c760",
   "metadata": {},
   "source": [
    "## 2.2. HTML Element Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76023097",
   "metadata": {},
   "source": [
    "## 2.3. HTML Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61869124",
   "metadata": {},
   "source": [
    "## 2.4. HTML Tree Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d8559",
   "metadata": {},
   "source": [
    "# 3. Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193473b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Let's get started with our first project with Beautiful Soup.\n",
    "    Import libraries if you install them before.\n",
    "    If you have not installed them, then install with pip on your command prompt or your jupyter notebook with !pip.\n",
    "'''\n",
    "# import relevant packages\n",
    "# Makes the plots appear within the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Two fundamental packages for doing data manipulation\n",
    "import numpy as np                   # http://www.numpy.org/\n",
    "import pandas as pd                  # http://pandas.pydata.org/\n",
    "\n",
    "#  for plotting data\n",
    "import matplotlib.pyplot as plt      # http://matplotlib.org/\n",
    "\n",
    "# Package to save/load Python structures in the \"Pickle\" format\n",
    "import pickle\n",
    "\n",
    "# Package query and download from web resources! Alternatives: URLlib2, URLlib3\n",
    "import requests\n",
    "\n",
    "# If you want HTML to make sense, you need soup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Some setup for display, helper libs, etc.\n",
    "from copy import deepcopy\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 110\n",
    "pd.options.mode.chained_assignment = None \n",
    "# Please make sure you have installed all of these libraries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182d3a1",
   "metadata": {},
   "source": [
    "<img src=\"./images/selenium.png\"  width=\"50\" height = \"50\" align=\"left\"/> \n",
    "\n",
    "# 4. Selenium \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c76de5",
   "metadata": {},
   "source": [
    "# 5. Scrapy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425df720",
   "metadata": {},
   "source": [
    "# 6. Challanges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe29c81",
   "metadata": {},
   "source": [
    "# 7. References\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "https://www.dataquest.io/blog/web-scraping-python-using-beautiful-soup/#tve-jump-1788432a71d\n",
    "\n",
    "https://developer.mozilla.org/en-US/docs/Web/HTML/Element\n",
    "\n",
    "https://medium.com/geekculture/web-scraping-cheat-sheet-2021-python-for-web-scraping-cad1540ce21c#b81d\n",
    "\n",
    "https://trends.google.com/trends/yis/2021/DE/\n",
    "\n",
    "https://blog.google/products/search/15-tips-getting-most-out-google-trends/\n",
    "\n",
    "\n",
    "Do not miss checking out the Social Comquant Workshop 10 at: https://github.com/strohne/autocol\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
